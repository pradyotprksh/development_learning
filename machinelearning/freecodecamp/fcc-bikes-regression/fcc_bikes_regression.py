# -*- coding: utf-8 -*-
"""fcc-bikes-regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bzLV47Pjrg7Wg-xMu8vssa-SglRy2agq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
import copy
import seaborn as sns
import tensorflow as tf
from sklearn.linear_model import LinearRegression

"""Dataset from https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand"""

dataset_cols = ["bike_count", "hour", "temp", "humidity", "wind", "visibility", "dew_pt_temp", "radiation", "rain", "snow", "functional"]
df = pd.read_csv("SeoulBikeData.csv").drop(["Date", "Holiday", "Seasons"], axis = 1)

df.head()

df.columns = dataset_cols

df.head()

df["functional"] = (df["functional"] == "Yes").astype(int)

df.head()

df = df[df["hour"] == 12]

df.head()

df = df.drop(["hour"], axis = 1)

df.head()

for label in df.columns[1:]:
  plt.scatter(df[label], df["bike_count"])
  plt.title(label)
  plt.ylabel("Bike Count at Noon")
  plt.xlabel(label)
  plt.show()

df = df.drop(["wind", "visibility", "functional"], axis = 1)

df.head()

"""# Train/Valid/Test Dataset"""

train, valid, test = np.split(df.sample(frac = 1), [int(0.6 * len(df)), int(0.8 * len(df))])

def get_xy(dataframe, y_label, x_labels=None):
  dataframe = copy.deepcopy(dataframe)
  if x_labels is None:
    X = dataframe[[c for c in dataframe.columns if c != y_label]].values
  else:
    if (len(x_labels) == 1):
      X = dataframe[x_labels[0]].values.reshape(-1, 1)
    else:
      X = dataframe[x_labels].values
  y = dataframe[y_label].values.reshape(-1, 1)
  data = np.hstack((X, y))
  return data, X, y

_, X_train_temp, y_train_temp = get_xy(train, "bike_count", ["temp"])
_, X_valid_temp, y_valid_temp = get_xy(valid, "bike_count", ["temp"])
_, X_test_temp, y_test_temp = get_xy(test, "bike_count", ["temp"])

temp_reg = LinearRegression()
temp_reg.fit(X_train_temp, y_train_temp)

temp_reg.score(X_test_temp, y_test_temp)

plt.scatter(X_train_temp, y_train_temp, label = "Data", color = "blue")
x = tf.linspace(-20, 40, 100)
plt.plot(x, temp_reg.predict(np.array(x).reshape(-1, 1)), label = "Fit", color = "red", linewidth = 3)
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of Bikes")
plt.xlabel("Temp")
plt.show()

"""# Multiple Linear Regression"""

df.columns

train, valid, test = np.split(df.sample(frac = 1), [int(0.6 * len(df)), int(0.8 * len(df))])
_, X_train_all, y_train_all = get_xy(train, "bike_count", df.columns[1:])
_, X_valid_all, y_valid_all = get_xy(valid, "bike_count", df.columns[1:])
_, X_test_all, y_test_all = get_xy(test, "bike_count", df.columns[1:])

all_reg = LinearRegression()
all_reg.fit(X_train_all, y_train_all)

all_reg.score(X_test_all, y_test_all)

"""# Regression with Neural Net"""

def plot_loss(history):
  plt.plot(history.history["loss"], label = "loss ")
  plt.plot(history.history["val_loss"], label = "val_oss")
  plt.xlabel("Epoch")
  plt.ylabel("MSE")
  plt.legend()
  plt.grid(True)
  plt.show()

temp_normalizer = tf.keras.layers.Normalization(input_shape = (1,), axis = None)
temp_normalizer.adapt(X_train_temp.reshape(-1))

temp_nn_model = tf.keras.models.Sequential([
    temp_normalizer,
    tf.keras.layers.Dense(units = 1)
])

temp_nn_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1), loss = "mean_squared_error")

history = temp_nn_model.fit(
    X_train_temp.reshape(-1), y_train_temp,
    epochs = 1000,
    validation_data = (X_valid_temp, y_valid_temp)
)

plot_loss(history)

plt.scatter(X_train_temp, y_train_temp, label = "Data", color = "blue")
x = tf.linspace(-20, 40, 100)
plt.plot(x, temp_nn_model.predict(np.array(x).reshape(-1, 1)), label = "Fit", color = "red", linewidth = 3)
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of Bikes")
plt.xlabel("Temp")
plt.show()

"""# Neural Net"""

temp_normalizer = tf.keras.layers.Normalization(input_shape = (1,), axis = None)
temp_normalizer.adapt(X_train_temp.reshape(-1))

nn_model = tf.keras.models.Sequential([
    temp_normalizer,
    tf.keras.layers.Dense(units = 32, activation = "relu"),
    tf.keras.layers.Dense(units = 32, activation = "relu"),
    tf.keras.layers.Dense(units = 32, activation = "relu"),
    tf.keras.layers.Dense(units = 1)
])

nn_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = "mean_squared_error")

history = nn_model.fit(
    X_train_temp, y_train_temp,
    epochs = 100,
    validation_data = (X_valid_temp, y_valid_temp),
    verbose = 0,
)

plot_loss(history)

plt.scatter(X_train_temp, y_train_temp, label = "Data", color = "blue")
x = tf.linspace(-20, 40, 100)
plt.plot(x, nn_model.predict(np.array(x).reshape(-1, 1)), label = "Fit", color = "red", linewidth = 3)
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of Bikes")
plt.xlabel("Temp")
plt.show()

all_normalizer = tf.keras.layers.Normalization(input_shape = (6,), axis = -1)
all_normalizer.adapt(X_train_all)

nn_model = tf.keras.models.Sequential([
    all_normalizer,
    tf.keras.layers.Dense(units = 32, activation = "relu"),
    tf.keras.layers.Dense(units = 32, activation = "relu"),
    tf.keras.layers.Dense(units = 1)
])
nn_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = "mean_squared_error")

history = nn_model.fit(
    X_train_all, y_train_all,
    epochs = 100,
    validation_data = (X_valid_all, y_valid_all),
    verbose = 0,
)

plot_loss(history)

# Calculate the MSE for LR and NN
y_pred_lr = all_reg.predict(X_test_all)
y_pred_nn = nn_model.predict(X_test_all)

def MSE(y_pred, y_real):
  return (np.square(y_pred - y_real)).mean()

MSE(y_pred_lr, y_test_all)

MSE(y_pred_nn, y_test_all)

ax = plt.axes(aspect = "equal")
plt.scatter(y_test_all, y_pred_lr, label = "Lin Reg Preds")
plt.scatter(y_test_all, y_pred_nn, label = "NN Preds")
plt.xlabel("True values")
plt.ylabel("Predictions")
lims = [0, 1800]
plt.xlim(lims)
plt.ylim(lims)
plt.legend()
_ = plt.plot(lims, lims, color = "red")

